{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This notebook takes input a csv file and loops through a list of DOIs re-formating the author names to the proper format: `last, first MI`. The parsed names are validate against the Pubs Warehouse publications web-service. If names are not found in PubsWarehouse, it will try finding them in Peter's Swheitzer's web-service. There is a third option, not yet implemented where, if a name is not found with the previous two web-services, sciencebase people web-service can be the next tool to use. (TODO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import requests\n",
    "import getpass\n",
    "from IPython.display import display\n",
    "\n",
    "sys.path.append('/Users/v1g/Projects/usgs_datatools')\n",
    "\n",
    "from usgs_datatools import doi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "username = \"admin@usgs.gov\"\n",
    "password = \"admin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doi_session = doi.DoiSession(env='local')\n",
    "doi_session.doi_authenticate(username, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This method takes two lists that contain the full name and required parameters for Pubs Warehouse web-service.\n",
    "    It parses the json response looking for author names that match both the first and last name.\n",
    "    Returns the pubs warehouse name and orcid if a match is found.\n",
    "'''\n",
    "\n",
    "def search_pubs_warehouse(name, params):\n",
    "    proper_name = {}\n",
    "    PUB_URL = \"https://pubs.er.usgs.gov/pubs-services/publication/\"\n",
    "    PUB_PARAMS = {'format': 'json', 'contributor': params}\n",
    "    pub_request = requests.get(url = PUB_URL, params=PUB_PARAMS)\n",
    "    print pub_request.url\n",
    "    data = pub_request.json()\n",
    "    for record in data['records']:\n",
    "        if 'authors' in record['contributors']:\n",
    "            for author in record['contributors']['authors']:\n",
    "                if  name[0] in author['text'] and name[1] in author['text']:\n",
    "                    proper_name['authorName'] = author['family'] + \", \" + author['given']\n",
    "                    if 'orcid' in author:\n",
    "                        orcid = author['orcid'].split(\"/\")[-1:]\n",
    "                        proper_name['orcId'] = orcid[0]\n",
    "                    return proper_name\n",
    "    return proper_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This method takes two lists that contain the full name and required parameters for Peter's web-service.\n",
    "    It parses the json response looking for author names that match both the first and last name.\n",
    "    Returns the author name and orcid if a match is found.\n",
    "'''\n",
    "\n",
    "def search_peter_service(name, params):\n",
    "    proper_name = {}\n",
    "    PETER_URL = \"https://geo-nsdi.er.usgs.gov/contacts.php\"\n",
    "    PETER_PARAMS = [{'format': 'json', 'givenname': params[0], 'sn': params[1]},\n",
    "                    {'format': 'json', 'givenname': params[1], 'sn': params[0]}]\n",
    "    for param_list in PETER_PARAMS:\n",
    "        peter_request = requests.get(url = PETER_URL, params=param_list)\n",
    "        print peter_request.url\n",
    "        try:\n",
    "            data = peter_request.json()\n",
    "        except:\n",
    "            continue\n",
    "        for contact in data['contacts']:\n",
    "            if  name[0] in contact['cntperp']['cntper'] and name[1] in contact['cntperp']['cntper']:\n",
    "                proper_name['authorName'] = contact['cntperp']['name']['last'] + \", \" + \\\n",
    "                                            contact['cntperp']['name']['first'] + \" \" + \\\n",
    "                                            contact['cntperp']['name']['middle']\n",
    "                if 'onlink' in contact:\n",
    "                    orcid = contact['onlink'].split(\"/\")[-1:]\n",
    "                    proper_name['orcId'] = orcid[0]\n",
    "                return proper_name\n",
    "            \n",
    "    return proper_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This method takes the full name as a list and runs a few validation checks before calling the web-services.\n",
    "    Returns a valid author name.\n",
    "'''\n",
    "\n",
    "def validate(name):\n",
    "    initials = []\n",
    "    name_params = []\n",
    "    proper_name = {}\n",
    "    stripped_name = []\n",
    "    name_strings = re.findall(r'\\w+', name)\n",
    "\n",
    "    if len(name_strings) < 2:\n",
    "        print \"WARNING !!!!! NAME CONTAINS ONLY 1 STRNG!!!!!\"\n",
    "        proper_name['authorName'] = name\n",
    "        proper_name['nameType'] = \"Personal\"\n",
    "        return proper_name\n",
    "\n",
    "    #strip the initials\n",
    "    for string in name_strings:\n",
    "        if len(string) > 1:\n",
    "            stripped_name.append(string)\n",
    "            name_params.append(string)\n",
    "        else:\n",
    "            initials.append(string)\n",
    "\n",
    "    if len(stripped_name) > 3:\n",
    "        print \"WARNING !!!!! Name too long. Possible organization\"\n",
    "        proper_name['authorName'] = name\n",
    "        proper_name['nameType'] = \"Organizational\"\n",
    "        return proper_name\n",
    "\n",
    "    \n",
    "    if len(stripped_name) < 2:\n",
    "        print \"WARNING !!!!! Name must have at least 2 strings: family name and given name!!!!!\"\n",
    "        proper_name['authorName'] = name\n",
    "        proper_name['nameType'] = \"Personal\"\n",
    "        return proper_name\n",
    "\n",
    "        \n",
    "    proper_name = search_pubs_warehouse(stripped_name, name_params)\n",
    "    if not proper_name:\n",
    "        proper_name = search_peter_service(stripped_name, name_params)\n",
    "    #if not proper_name:\n",
    "        #proper_name = search_sciencebase(stripped_name, name_params)\n",
    "    if not proper_name:\n",
    "        proper_name['authorName'] = name\n",
    "        \n",
    "    proper_name['nameType'] = \"Personal\"\n",
    "    return proper_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This method takes a DOI identifier, retrieves the full json record from DMAPI, and replaces the improper author\n",
    "    entries with proper formated authors.\n",
    "    The return is a DOI object\n",
    "'''\n",
    "\n",
    "import re\n",
    "import requests\n",
    "\n",
    "def get_proper_author_list(doi):\n",
    "    proper_author_list = []\n",
    "    doi_json = doi_session.get_doi(doi)\n",
    "    \n",
    "    #add IPDS fields\n",
    "    doi_json['noPublicationIdAvailable'] = True\n",
    "    doi_json['noDataReleaseAvailableReason'] = 'LEGACY_DATA'\n",
    "    \n",
    "    #decode text fields\n",
    "    if doi_json['description']:\n",
    "        description = doi_json['description'].encode('ascii','replace')\n",
    "        doi_json['description'] = description\n",
    "    if doi_json['title']:\n",
    "        title = doi_json['title'].encode('ascii','replace')\n",
    "        doi_json['title'] = title\n",
    "\n",
    "    #if date or dateType are null, make both null\n",
    "    if not doi_json['date']:\n",
    "        doi_json['dateType'] = ''\n",
    "    if not doi_json['dateType']:\n",
    "        doi_json['date'] = ''\n",
    "\n",
    "    index = 0\n",
    "    for authors_entry in doi_json['authors']:\n",
    "        print \"IMPROPER NAME: \" + authors_entry['authorName']\n",
    "        author_names = authors_entry['authorName'].split(';')\n",
    "        print \"SIZE: \" + str(len(author_names))\n",
    "\n",
    "        for name in author_names:\n",
    "            proper_name = validate(name)\n",
    "            if not proper_name['authorName']:\n",
    "                continue\n",
    "            proper_name['position'] = index\n",
    "            proper_author_list.append(proper_name)\n",
    "            index += 1\n",
    "            \n",
    "    doi_json['authors'] = proper_author_list\n",
    "\n",
    "    return doi_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This code retrieves a list of DOI identifiers from a csv file and for each DOI will try to format the author list \n",
    "    and then submit an update request to DMAPI to save the new record to database and Datacite.\n",
    "    Failed POSTs will append the DOI identifier to a local txt file.\n",
    "'''\n",
    "\n",
    "import csv\n",
    "\n",
    "failed_list = []\n",
    "\n",
    "with open('/Users/v1g/Desktop/remove/pattern_semicolon.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    for doi in csv_reader:\n",
    "        print \"\\n\\n\" + doi[0]\n",
    "        new_payload = get_proper_author_list(doi[0])\n",
    "        update_req = doi_session.doi_update(new_payload)\n",
    "        error_msgs = [\"Misformatted Date\", \"dateType\"]\n",
    "        if any(x in update_req['message'] for x in error_msgs):\n",
    "            new_payload['date'] = ''\n",
    "            new_payload['dateType'] = ''\n",
    "            update_req = doi_session.doi_update(new_payload)\n",
    "        if any(x in update_req['message'] for x in error_msgs):\n",
    "            new_payload['date'] = ''\n",
    "            new_payload['dateType'] = ''\n",
    "            update_req = doi_session.doi_update(new_payload)\n",
    "        print \"\\n\\n\"\n",
    "        print new_payload['authors']\n",
    "        print update_req\n",
    "        \n",
    "        if update_req['error'] > 202:\n",
    "            failed_list.append(doi[0])\n",
    "\n",
    "print failed_list\n",
    "with open('/Users/v1g/Desktop/remove/failed_list.txt', 'w') as txt_file:\n",
    "    for row in failed_list:\n",
    "        txt_file.write(row + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
