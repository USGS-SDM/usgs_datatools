{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This notebook provides an example of running through and making a bunch of DOI updates based on records in ScienceBase. In this case, we had previously reserved DOIs, all pointing at ScienceBase Items as their de-referencing URLs, and we now need to finalize the DOIs and turn them on for real. It works with Brandon Serna's usgs_datatools package, where the latest version works with the new DOI REST API. Most of the parts and pieces of this should be fairly easily reused by others needing to do something similar.\n",
    "\n",
    "The first few blocks here do all the same things Brandon has shown in other examples, setting up a session with the DOI tool to do work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import requests\n",
    "import getpass\n",
    "\n",
    "from IPython.display import display\n",
    "from usgs_datatools import doi\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.exceptions import ConnectionError\n",
    "\n",
    "pubs_adapter = HTTPAdapter(max_retries=3)\n",
    "pubs_session = requests.Session()\n",
    "pubs_session.mount('https://pubs.er.usgs.gov', pubs_adapter)\n",
    "\n",
    "peter_adapter = HTTPAdapter(max_retries=3)\n",
    "peter_session = requests.Session()\n",
    "peter_session.mount('https://geo-nsdi.er.usgs.gov', peter_adapter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = \"vgarbulet@contractor.usgs.gov\"\n",
    "password = \"password\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doi_session = doi.DoiSession(env='beta')\n",
    "doi_session.doi_authenticate(username, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_pubs_warehouse(name, params):\n",
    "    proper_name = {}\n",
    "    PUB_URL = \"https://pubs.er.usgs.gov/pubs-services/publication/\"\n",
    "    PUB_PARAMS = {'format': 'json', 'contributor': params}\n",
    "    try:\n",
    "        pub_request = pubs_session.get(url = PUB_URL, params=PUB_PARAMS)\n",
    "    except ConnectionError as ce:\n",
    "        print(ce)\n",
    "        exit(1)\n",
    "            \n",
    "    #print(pub_request.url)\n",
    "    data = pub_request.json()\n",
    "    for record in data['records']:\n",
    "        if 'authors' in record['contributors']:\n",
    "            for author in record['contributors']['authors']:\n",
    "                if  name[0] in author['text'] and name[1] in author['text']:\n",
    "                    if 'family' in author and 'given' in author:\n",
    "                        proper_name['authorName'] = author['family'] + \", \" + author['given']\n",
    "                    else:\n",
    "                        proper_name['authorName'] = name\n",
    "                    if 'orcid' in author:\n",
    "                        orcid = author['orcid'].split(\"/\")[-1:]\n",
    "                        proper_name['orcId'] = orcid[0]\n",
    "                    return proper_name\n",
    "    \n",
    "    return proper_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_peter_service(name, params):\n",
    "    proper_name = {}\n",
    "    PETER_URL = \"https://geo-nsdi.er.usgs.gov/contacts.php\"\n",
    "    PETER_PARAMS = [{'format': 'json', 'givenname': params[0], 'sn': params[1]},\n",
    "                    {'format': 'json', 'givenname': params[1], 'sn': params[0]}]\n",
    "    for param_list in PETER_PARAMS:\n",
    "        try:\n",
    "            peter_request = peter_session.get(url = PETER_URL, params=param_list)\n",
    "        except ConnectionError as ce:\n",
    "            print(ce)\n",
    "            exit(1)\n",
    "        try:\n",
    "            data = peter_request.json()\n",
    "        except:\n",
    "            continue\n",
    "        for contact in data['contacts']:\n",
    "            if  name[0] in contact['cntperp']['cntper'] and name[1] in contact['cntperp']['cntper']:\n",
    "                proper_name['authorName'] = contact['cntperp']['name']['last'] + \", \" + \\\n",
    "                                            contact['cntperp']['name']['first'] + \" \" + \\\n",
    "                                            contact['cntperp']['name']['middle']\n",
    "                if 'onlink' in contact:\n",
    "                    orcid = contact['onlink'].split(\"/\")[-1:]\n",
    "                    proper_name['orcId'] = orcid[0]\n",
    "                return proper_name\n",
    "            \n",
    "    return proper_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(name):\n",
    "    initials = []\n",
    "    name_params = []\n",
    "    proper_name = {}\n",
    "    stripped_name = []\n",
    "    name_strings = re.findall(r'\\w+', name)\n",
    "\n",
    "    if len(name_strings) < 2:\n",
    "        print(\"WARNING !!!!! NAME CONTAINS ONLY 1 STRNG!!!!!\")\n",
    "        proper_name['authorName'] = name\n",
    "        proper_name['nameType'] = \"Personal\"\n",
    "        return proper_name\n",
    "\n",
    "    #strip the initials\n",
    "    for string in name_strings:\n",
    "        if len(string) > 1:\n",
    "            stripped_name.append(string.strip())\n",
    "            name_params.append(string.strip())\n",
    "        else:\n",
    "            initials.append(string.strip())\n",
    "\n",
    "    if len(stripped_name) > 3:\n",
    "        print(\"WARNING !!!!! Name too long. Possible organization\")\n",
    "        proper_name['authorName'] = name\n",
    "        proper_name['nameType'] = \"Organizational\"\n",
    "        return proper_name\n",
    "\n",
    "    \n",
    "    if len(stripped_name) < 2:\n",
    "        print(\"WARNING !!!!! Name must have at least 2 strings: family name and given name!!!!!\")\n",
    "        proper_name['authorName'] = name\n",
    "        proper_name['nameType'] = \"Personal\"\n",
    "        return proper_name\n",
    "\n",
    "        \n",
    "    proper_name = search_pubs_warehouse(stripped_name, name_params)\n",
    "    if not proper_name:\n",
    "        proper_name = search_peter_service(stripped_name, name_params)\n",
    "    #if not proper_name:\n",
    "        #proper_name = search_sciencebase(stripped_name, name_params)\n",
    "    if not proper_name:\n",
    "        proper_name['authorName'] = name\n",
    "        \n",
    "    proper_name['nameType'] = \"Personal\"\n",
    "    return proper_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "\n",
    "def get_proper_author_list(doi):\n",
    "    proper_author_list = []\n",
    "    doi_json = doi_session.get_doi(doi)\n",
    "    #print(doi_json)\n",
    "    \n",
    "    # Return 0 if GET request failed\n",
    "    if 'error' in doi_json:\n",
    "        return 0\n",
    "    \n",
    "    #add IPDS fields\n",
    "    if len(doi_json['ipdsNumbers']) < 1:\n",
    "            doi_json['noDataReleaseAvailableReason'] = 'LEGACY_DATA'\n",
    "\n",
    "    doi_json['noPublicationIdAvailable'] = True\n",
    "\n",
    "    #decode text fields\n",
    "    if doi_json['description']:\n",
    "        description = str(doi_json['description']).encode('ascii','replace')\n",
    "        doi_json['description'] = description.decode(\"utf-8\")\n",
    "    if doi_json['title']:\n",
    "        title = str(doi_json['title']).encode('ascii','replace')\n",
    "        doi_json['title'] = title.decode(\"utf-8\")\n",
    "\n",
    "    #if date or dateType are null, make both null\n",
    "    \n",
    "    index = 0\n",
    "    for authors_entry in doi_json['authors']:\n",
    "        print(\"IMPROPER NAME: \" + authors_entry['authorName'])\n",
    "        author_names = authors_entry['authorName'].split(';')\n",
    "        print(\"SIZE: \" + str(len(author_names)))\n",
    "\n",
    "        for name in author_names:\n",
    "            proper_name = validate(name.strip())\n",
    "            if not proper_name['authorName']:\n",
    "                continue\n",
    "            proper_name['position'] = index\n",
    "            proper_author_list.append(proper_name)\n",
    "            index += 1\n",
    "            \n",
    "    doi_json['authors'] = proper_author_list\n",
    "\n",
    "    return doi_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "success_file=open(\"success_report.txt\", \"a+\")\n",
    "failure_file=open(\"failure_report.txt\", \"a+\")\n",
    "success_list=open(\"success_list.txt\", \"a+\")\n",
    "\n",
    "with open('/Users/remoteuser/JupiterNotebooks/DMAPI/pattern_semicolon_small.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    for doi in csv_reader:\n",
    "        print(\"\\n\\n\" + doi[0])\n",
    "        new_payload = get_proper_author_list(doi[0])\n",
    "\n",
    "        if new_payload == 0:\n",
    "            failure_file.write(doi[0] + \"\\n\" + json.dumps(new_payload) + \" DOI NOT FOUND!!!!!!!!\\n\")\n",
    "            continue\n",
    "            \n",
    "        print(\"UPDATES TO:\")\n",
    "        print(json.dumps(new_payload['authors'], indent=4))\n",
    "\n",
    "        #answer = input('Do you want to update database with new author?(y/n)')\n",
    "        answer = 'y'\n",
    "        if answer == 'y':\n",
    "            update_req = doi_session.doi_update(new_payload)\n",
    "            #print(update_req)\n",
    "\n",
    "            if \"error\" in update_req and update_req['error'] > 202:\n",
    "                print(\"\\nFAILURE:\\n\")\n",
    "                failure_file.write(doi[0] + \"\\n\")\n",
    "                failure_file.write(json.dumps(update_req))\n",
    "                failure_file.write(\"\\n\\n\")\n",
    "                continue\n",
    "\n",
    "            else:\n",
    "                print(\"\\nSUCCESS:\\n\")\n",
    "                success_list.write(\"\\n\\n\" + doi[0])\n",
    "                success_file.write(\"\\n\\n\" + doi[0])\n",
    "                success_file.write(\"\\nUPDATES TO:\\n\" + json.dumps(new_payload['authors'], indent=4))\n",
    "        \n",
    "        else:\n",
    "            failure_file.write(doi[0] + \"\\n\")\n",
    "            failure_file.write(\"UPDATES TO WRONG AUTHORS:\\n\" + json.dumps(new_payload['authors'], indent=4))\n",
    "            \n",
    "success_file.close()\n",
    "failure_file.close()\n",
    "txt_file.close()\n",
    "success_list.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
